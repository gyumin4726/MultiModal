import torch
import pandas as pd
from PIL import Image
from tqdm import tqdm
import torchvision.transforms as transforms
from config import device
from utils import extract_answer_letter
from vision_encoder import load_vision_encoder
from text_encoder import load_text_encoder
from language_model import load_language_model

def setup_models():
    """ëª¨ë“  ëª¨ë¸ ë¡œë”©"""
    print("ğŸ”„ Setting up MultiModal models...")
    
    # ë¹„ì „ ì¸ì½”ë” ë¡œë”©
    print("ğŸ“¸ Loading Vision Encoder (VMamba)...")
    vision_encoder = load_vision_encoder(
        model_name='vmamba_tiny_s1l8',
        pretrained_path='./vssm1_tiny_0230s_ckpt_epoch_264.pth',
        output_dim=768,
        frozen_stages=1
    )
    
    # í…ìŠ¤íŠ¸ ì¸ì½”ë” ë¡œë”©
    print("ğŸ“ Loading Text Encoder (sentence-transformers)...")
    text_encoder = load_text_encoder(
        model_type='default',
        output_dim=768
    )
    
    # ì–¸ì–´ ëª¨ë¸ ë¡œë”©
    print("ğŸ¤– Loading Language Model (microsoft/phi-2)...")
    language_model = load_language_model(model_name="microsoft/phi-2")
    
    # GPUë¡œ ì´ë™
    if torch.cuda.is_available():
        vision_encoder = vision_encoder.cuda()
        # text_encoderì™€ language_modelì€ ì´ë¯¸ ë‚´ë¶€ì ìœ¼ë¡œ GPU ì²˜ë¦¬ë¨
    
    print("âœ… All models loaded successfully!")
    return vision_encoder, text_encoder, language_model

def setup_image_transform():
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[123.675/255, 116.28/255, 103.53/255],
                           std=[58.395/255, 57.12/255, 57.375/255])
    ])

def create_multimodal_prompt(question, choices, vision_features=None, text_features=None):
    """ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    prompt = (
        "You are a helpful AI that answers multiple-choice questions based on images.\n"
        "Analyze the image carefully and select the best answer from the given choices.\n\n"
        f"Question: {question}\n"
        "Choices:\n"
    )
    
    # ì„ íƒì§€ ì¶”ê°€
    for i, choice in enumerate(choices):
        prompt += f"{chr(65+i)}. {choice}\n"
    
    prompt += "\nBased on the image, the answer is:"
    
    return prompt

def run_multimodal_inference():
    """ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹¤í–‰"""
    # ëª¨ë¸ ì„¤ì •
    vision_encoder, text_encoder, language_model = setup_models()
    transform = setup_image_transform()
    
    # ë°ì´í„° ë¡œë”©
    print("ğŸ“Š Loading test data...")
    test_data = pd.read_csv('./dev_test.csv')
    print(f"Total samples: {len(test_data)}")
    
    results = []
    
    print("ğŸš€ Starting inference...")
    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc="Processing"):
        try:
            # ì´ë¯¸ì§€ ë¡œë”© ë° ì „ì²˜ë¦¬
            image_path = row['img_path']
            image = Image.open(image_path).convert("RGB")
            image_tensor = transform(image).unsqueeze(0)  # (1, 3, 224, 224)
            
            if torch.cuda.is_available():
                image_tensor = image_tensor.cuda()
            
            # ì§ˆë¬¸ ë° ì„ íƒì§€
            question = row['Question']
            choices = [row['A'], row['B'], row['C'], row['D']]
            
            # 1. ë¹„ì „ ì¸ì½”ë”ë¡œ ì´ë¯¸ì§€ í”¼ì²˜ ì¶”ì¶œ
            with torch.no_grad():
                vision_features = vision_encoder(image_tensor)
            
            # 2. í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¡œ ì§ˆë¬¸ ì„ë² ë”© (ì„ íƒì‚¬í•­)
            question_embedding = text_encoder([question])
            
            # 3. ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = create_multimodal_prompt(question, choices)
            
            # 4. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            response = language_model.generate_text(
                prompt, 
                max_new_tokens=10,  # ì§§ì€ ë‹µë³€ë§Œ í•„ìš”
                temperature=0.0
            )
            
            # 5. ë‹µë³€ì—ì„œ ì•ŒíŒŒë²³ ì¶”ì¶œ
            predicted_answer = extract_answer_letter(response)
            
            results.append(predicted_answer)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (ì²˜ìŒ 5ê°œë§Œ)
            if idx < 5:
                print(f"\n--- Sample {idx} ---")
                print(f"Image: {image_path}")
                print(f"Question: {question}")
                print(f"Choices: {choices}")
                print(f"Response: {response}")
                print(f"Predicted: {predicted_answer}")
                print("-" * 50)
            
        except Exception as e:
            print(f"âŒ Error processing {row['ID']}: {e}")
            results.append("?")  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’
    
    print('\nâœ… Inference completed!')
    
    # ê²°ê³¼ ì €ì¥
    submission = pd.read_csv('./sample_submission.csv')
    submission['answer'] = results
    submission.to_csv('./multimodal_submission.csv', index=False)
    print("âœ… Results saved to 'multimodal_submission.csv'")
    
    # ê°„ë‹¨í•œ í†µê³„
    answer_counts = pd.Series(results).value_counts()
    print(f"\nğŸ“Š Answer distribution:")
    print(answer_counts)
    
    return results

if __name__ == "__main__":
    # ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹¤í–‰
    run_multimodal_inference() 