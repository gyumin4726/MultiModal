import torch
from PIL import Image
import torchvision.transforms as transforms
from config import seed_everything
from vision_encoder import load_vision_encoder
from text_encoder import load_text_encoder, list_available_models
from language_model import load_language_model

def test_vision_encoder():
    """ë¹„ì „ ì¸ì½”ë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Loading vision encoder...")
    try:
        vision_encoder = load_vision_encoder(
            model_name='vmamba_tiny_s1l8',
            pretrained_path='./vssm1_tiny_0230s_ckpt_epoch_264.pth',
            output_dim=768,
            frozen_stages=1
        )
        print("âœ… Vision encoder loaded successfully!")
        
        # GPU ë¡œë”©
        if torch.cuda.is_available():
            vision_encoder = vision_encoder.cuda()
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[123.675/255, 116.28/255, 103.53/255],
                               std=[58.395/255, 57.12/255, 57.375/255])
        ])
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë”©
        test_image_path = "input_images/TEST_000.jpg"
        try:
            image = Image.open(test_image_path).convert("RGB")
            image_tensor = transform(image).unsqueeze(0)  # (1, 3, 224, 224)
            
            if torch.cuda.is_available():
                image_tensor = image_tensor.cuda()
            
            # ë¹„ì „ ì¸ì½”ë” ì¶”ë¡ 
            with torch.no_grad():
                vision_features = vision_encoder(image_tensor)
                print(f"âœ… Vision features shape: {vision_features.shape}")
                print(f"âœ… Vision features norm: {vision_features.norm().item():.4f}")
                
        except FileNotFoundError:
            print("âš ï¸ Test image not found, creating dummy tensor for testing...")
            dummy_image = torch.randn(1, 3, 224, 224)
            if torch.cuda.is_available():
                dummy_image = dummy_image.cuda()
            
            with torch.no_grad():
                vision_features = vision_encoder(dummy_image)
                print(f"âœ… Vision features shape: {vision_features.shape}")
                print(f"âœ… Vision features norm: {vision_features.norm().item():.4f}")
        
        return vision_encoder
        
    except Exception as e:
        print(f"âŒ Error loading vision encoder: {e}")
        return None

def test_text_encoder():
    """í…ìŠ¤íŠ¸ ì¸ì½”ë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ“ Loading text encoder...")
    try:
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥
        print("\nğŸ“‹ Available text encoder models:")
        list_available_models()
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¸ì½”ë” ë¡œë”© (all-MiniLM-L6-v2)
        text_encoder = load_text_encoder(
            model_type='default',
            output_dim=768  # VMambaì™€ ë§ì¶¤
        )
        print("âœ… Text encoder loaded successfully!")
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
        test_texts = [
            "What is shown in this image?",
            "Describe the main objects in the picture.",
            "Can you identify the key features in this photo?",
            "What are the colors and shapes visible?"
        ]
        
        # í…ìŠ¤íŠ¸ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
        print(f"ğŸ”¤ Encoding {len(test_texts)} test sentences...")
        with torch.no_grad():
            text_features = text_encoder(test_texts)
            print(f"âœ… Text features shape: {text_features.shape}")
            print(f"âœ… Text features norm: {text_features.norm(dim=1).mean().item():.4f}")
            
            # ê°œë³„ ë¬¸ì¥ë³„ ê²°ê³¼
            for i, text in enumerate(test_texts):
                norm = text_features[i].norm().item()
                print(f"   ğŸ“„ Sentence {i+1}: norm={norm:.4f}")
        
        return text_encoder
        
    except Exception as e:
        print(f"âŒ Error loading text encoder: {e}")
        print("ğŸ’¡ Make sure sentence-transformers is installed: pip install sentence-transformers")
        return None

def test_language_model():
    """ì–¸ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¤– Loading language model...")
    try:
        language_model = load_language_model(model_name="microsoft/phi-2")
        print("âœ… Language model loaded successfully!")
        
        # í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        prompt = "Explain what a black hole is in simple terms."
        result = language_model.generate_text(prompt, max_new_tokens=100)
        print(f"Generated text: {result}")
        
        return language_model
        
    except Exception as e:
        print(f"âŒ Error loading language model: {e}")
        return None

if __name__ == "__main__":
    # ì‹œë“œ ê³ ì •
    seed_everything()
    
    print("ğŸš€ Starting complete MultiModal system test...")
    print("="*60)
    
    # ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ Testing VMamba Vision Encoder")
    print("-"*40)
    vision_encoder = test_vision_encoder()
    
    print("\n2ï¸âƒ£ Testing sentence-transformers Text Encoder")
    print("-"*40)
    text_encoder = test_text_encoder()
    
    print("\n3ï¸âƒ£ Testing microsoft/phi-2 Language Model")
    print("-"*40)
    language_model = test_language_model()
    
    # ìµœì¢… ê²°ê³¼
    print("\n" + "="*60)
    print("ğŸ“Š FINAL RESULTS:")
    print(f"   Vision Encoder (VMamba): {'âœ… OK' if vision_encoder else 'âŒ FAILED'}")
    print(f"   Text Encoder (BERT): {'âœ… OK' if text_encoder else 'âŒ FAILED'}")
    print(f"   Language Model (phi-2): {'âœ… OK' if language_model else 'âŒ FAILED'}")
    
    if all([vision_encoder, text_encoder, language_model]):
        print("\nğŸ‰ All three modules are working perfectly!")
        print("ğŸ”¥ Ready to implement full multimodal integration!")
        print("\nğŸ“‹ Current architecture:")
        print("   ğŸ–¼ï¸ Vision: VMamba (ì‚¬ì „í•™ìŠµ)")
        print("   ğŸ“ Text: sentence-transformers (ì‚¬ì „í•™ìŠµ)")  
        print("   ğŸ¤– LLM: microsoft/phi-2 (ì‚¬ì „í•™ìŠµ)")
    else:
        print("\nâš ï¸ Some modules need attention.")
        print("ğŸ”§ Please check the error messages above.") 