import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
import numpy as np


class TextEncoder(nn.Module):
    """transformers ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¸ì½”ë” ëª¨ë“ˆ (PyTorch 1.12.1 í˜¸í™˜)"""
    
    def __init__(self, 
                 model_name='sentence-transformers/all-MiniLM-L6-v2',
                 output_dim=768,
                 device=None,
                 max_length=512):
        super().__init__()
        
        self.model_name = model_name
        self.output_dim = output_dim
        self.max_length = max_length
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        
        # transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë”©
        print(f"Loading transformers model: {model_name}")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            
            # ëª¨ë¸ì˜ ì›ë˜ ì„ë² ë”© ì°¨ì› í™•ì¸
            self.native_dim = self.model.config.hidden_size
            print(f"Native embedding dimension: {self.native_dim}")
            
        except Exception as e:
            print(f"Failed to load {model_name}, falling back to bert-base-uncased")
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
            self.model = AutoModel.from_pretrained('bert-base-uncased')
            self.model.to(self.device)
            self.model.eval()
            self.native_dim = 768
        
        # ì¶œë ¥ ì°¨ì›ì´ ë‹¤ë¥´ë©´ projection layer ì¶”ê°€
        if self.native_dim != output_dim:
            self.projection = nn.Linear(self.native_dim, output_dim)
            self.projection.to(self.device)
            print(f"Added projection layer: {self.native_dim} -> {output_dim}")
        else:
            self.projection = None
            print(f"No projection needed (native dim = output dim = {output_dim})")
    
    def mean_pooling(self, model_output, attention_mask):
        """í‰ê·  í’€ë§ì„ í†µí•œ ë¬¸ì¥ ì„ë² ë”© ìƒì„±"""
        token_embeddings = model_output[0]  # First element contains all token embeddings
        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)
        
    def encode_text(self, texts):
        """
        Args:
            texts (list or str): í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
            
        Returns:
            torch.Tensor: í…ìŠ¤íŠ¸ í”¼ì²˜ ë²¡í„° (B, output_dim)
        """
        # ë‹¨ì¼ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(texts, str):
            texts = [texts]
        
        # í† í¬ë‚˜ì´ì§•
        encoded_input = self.tokenizer(
            texts, 
            padding=True, 
            truncation=True, 
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        # GPUë¡œ ì´ë™
        encoded_input = {k: v.to(self.device) for k, v in encoded_input.items()}
        
        # ëª¨ë¸ ì¶”ë¡ 
        with torch.no_grad():
            model_output = self.model(**encoded_input)
            
            # í‰ê·  í’€ë§ìœ¼ë¡œ ë¬¸ì¥ ì„ë² ë”© ìƒì„±
            embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])
            
            # L2 ì •ê·œí™”
            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
        
        # Projectionì´ í•„ìš”í•˜ë©´ ì ìš©
        if self.projection is not None:
            embeddings = self.projection(embeddings)
        
        return embeddings
        
    def forward(self, texts):
        return self.encode_text(texts)


class MultilingualTextEncoder(TextEncoder):
    """ë‹¤êµ­ì–´ ì§€ì› í…ìŠ¤íŠ¸ ì¸ì½”ë”"""
    
    def __init__(self, output_dim=768, device=None):
        # ë‹¤êµ­ì–´ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
        super().__init__(
            model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
            output_dim=output_dim,
            device=device
        )


class HighPerformanceTextEncoder(TextEncoder):
    """ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ì¸ì½”ë”"""
    
    def __init__(self, output_dim=768, device=None):
        # ì„±ëŠ¥ ìš°ìˆ˜í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš© (fallback í¬í•¨)
        try:
            super().__init__(
                model_name='sentence-transformers/all-mpnet-base-v2',
                output_dim=output_dim,
                device=device
            )
        except:
            # fallback to BERT
            super().__init__(
                model_name='bert-base-uncased',
                output_dim=output_dim,
                device=device
            )


def load_text_encoder(model_type='default', **kwargs):
    """í…ìŠ¤íŠ¸ ì¸ì½”ë” ë¡œë”© í•¨ìˆ˜
    
    Args:
        model_type (str): 'default', 'multilingual', 'high_performance'
        **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
    """
    if model_type == 'multilingual':
        return MultilingualTextEncoder(**kwargs)
    elif model_type == 'high_performance':
        return HighPerformanceTextEncoder(**kwargs)
    else:  # default
        return TextEncoder(**kwargs)


# ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ë“¤ (PyTorch 1.12.1 í˜¸í™˜)
AVAILABLE_MODELS = {
    'sentence-transformers/all-MiniLM-L6-v2': {
        'description': 'ê°€ë³ê³  ë¹ ë¥¸ ëª¨ë¸ (384ì°¨ì›)',
        'embedding_dim': 384,
        'multilingual': False
    },
    'bert-base-uncased': {
        'description': 'BERT ê¸°ë³¸ ëª¨ë¸ (768ì°¨ì›)', 
        'embedding_dim': 768,
        'multilingual': False
    },
    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': {
        'description': 'ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸ (384ì°¨ì›)',
        'embedding_dim': 384,
        'multilingual': True
    },
    'distilbert-base-uncased': {
        'description': 'DistilBERT ê¸°ë°˜ (768ì°¨ì›)',
        'embedding_dim': 768,
        'multilingual': False
    }
}

def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    print("ğŸ“‹ Available pre-trained text encoder models (PyTorch 1.12.1 compatible):")
    print("-" * 70)
    for model_name, info in AVAILABLE_MODELS.items():
        print(f"ğŸ”¹ {model_name}")
        print(f"   - {info['description']}")
        print(f"   - Embedding dimension: {info['embedding_dim']}")
        print(f"   - Multilingual: {'Yes' if info['multilingual'] else 'No'}")
        print()


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    list_available_models()
    
    # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¸ì½”ë” í…ŒìŠ¤íŠ¸
    encoder = load_text_encoder()
    
    test_texts = [
        "What is shown in this image?",
        "Describe the main objects in the picture.",
        "Can you identify the key features?"
    ]
    
    embeddings = encoder(test_texts)
    print(f"Text embeddings shape: {embeddings.shape}")
    print(f"Embeddings norm: {embeddings.norm(dim=1)}") 