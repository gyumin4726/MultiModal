import torch
import torch.nn as nn
from sentence_transformers import SentenceTransformer
import numpy as np


class TextEncoder(nn.Module):
    """sentence-transformers ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¸ì½”ë” ëª¨ë“ˆ"""
    
    def __init__(self, 
                 model_name='all-MiniLM-L6-v2',
                 output_dim=768,
                 device=None):
        super().__init__()
        
        self.model_name = model_name
        self.output_dim = output_dim
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ì‚¬ì „ í•™ìŠµëœ sentence-transformers ëª¨ë¸ ë¡œë”©
        print(f"Loading sentence-transformers model: {model_name}")
        self.sentence_model = SentenceTransformer(model_name, device=self.device)
        
        # ëª¨ë¸ì˜ ì›ë˜ ì„ë² ë”© ì°¨ì› í™•ì¸
        self.native_dim = self.sentence_model.get_sentence_embedding_dimension()
        print(f"Native embedding dimension: {self.native_dim}")
        
        # ì¶œë ¥ ì°¨ì›ì´ ë‹¤ë¥´ë©´ projection layer ì¶”ê°€
        if self.native_dim != output_dim:
            self.projection = nn.Linear(self.native_dim, output_dim)
            print(f"Added projection layer: {self.native_dim} -> {output_dim}")
        else:
            self.projection = None
            print(f"No projection needed (native dim = output dim = {output_dim})")
        
    def encode_text(self, texts):
        """
        Args:
            texts (list or str): í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
            
        Returns:
            torch.Tensor: í…ìŠ¤íŠ¸ í”¼ì²˜ ë²¡í„° (B, output_dim)
        """
        # ë‹¨ì¼ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(texts, str):
            texts = [texts]
        
        # sentence-transformersë¡œ ì„ë² ë”© ìƒì„± (ì´ë¯¸ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸)
        with torch.no_grad():
            embeddings = self.sentence_model.encode(
                texts,
                convert_to_tensor=True,
                device=self.device,
                normalize_embeddings=True  # L2 ì •ê·œí™” ì ìš©
            )
        
        # Projectionì´ í•„ìš”í•˜ë©´ ì ìš©
        if self.projection is not None:
            embeddings = self.projection(embeddings)
        
        return embeddings
        
    def forward(self, texts):
        return self.encode_text(texts)


class MultilingualTextEncoder(TextEncoder):
    """ë‹¤êµ­ì–´ ì§€ì› í…ìŠ¤íŠ¸ ì¸ì½”ë”"""
    
    def __init__(self, output_dim=768, device=None):
        # ë‹¤êµ­ì–´ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
        super().__init__(
            model_name='paraphrase-multilingual-MiniLM-L12-v2',
            output_dim=output_dim,
            device=device
        )


class HighPerformanceTextEncoder(TextEncoder):
    """ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ì¸ì½”ë”"""
    
    def __init__(self, output_dim=768, device=None):
        # ì„±ëŠ¥ ìš°ìˆ˜í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
        super().__init__(
            model_name='all-mpnet-base-v2',
            output_dim=output_dim,
            device=device
        )


def load_text_encoder(model_type='default', **kwargs):
    """í…ìŠ¤íŠ¸ ì¸ì½”ë” ë¡œë”© í•¨ìˆ˜
    
    Args:
        model_type (str): 'default', 'multilingual', 'high_performance'
        **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
    """
    if model_type == 'multilingual':
        return MultilingualTextEncoder(**kwargs)
    elif model_type == 'high_performance':
        return HighPerformanceTextEncoder(**kwargs)
    else:  # default
        return TextEncoder(**kwargs)


# ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ë“¤
AVAILABLE_MODELS = {
    'all-MiniLM-L6-v2': {
        'description': 'ê°€ë³ê³  ë¹ ë¥¸ ëª¨ë¸ (384ì°¨ì›)',
        'embedding_dim': 384,
        'multilingual': False
    },
    'all-mpnet-base-v2': {
        'description': 'ê³ ì„±ëŠ¥ ëª¨ë¸ (768ì°¨ì›)', 
        'embedding_dim': 768,
        'multilingual': False
    },
    'paraphrase-multilingual-MiniLM-L12-v2': {
        'description': 'ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸ (384ì°¨ì›)',
        'embedding_dim': 384,
        'multilingual': True
    },
    'all-distilroberta-v1': {
        'description': 'DistilRoBERTa ê¸°ë°˜ (768ì°¨ì›)',
        'embedding_dim': 768,
        'multilingual': False
    }
}

def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    print("ğŸ“‹ Available pre-trained text encoder models:")
    print("-" * 60)
    for model_name, info in AVAILABLE_MODELS.items():
        print(f"ğŸ”¹ {model_name}")
        print(f"   - {info['description']}")
        print(f"   - Embedding dimension: {info['embedding_dim']}")
        print(f"   - Multilingual: {'Yes' if info['multilingual'] else 'No'}")
        print()


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    list_available_models()
    
    # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¸ì½”ë” í…ŒìŠ¤íŠ¸
    encoder = load_text_encoder()
    
    test_texts = [
        "What is shown in this image?",
        "Describe the main objects in the picture.",
        "Can you identify the key features?"
    ]
    
    embeddings = encoder(test_texts)
    print(f"Text embeddings shape: {embeddings.shape}")
    print(f"Embeddings norm: {embeddings.norm(dim=1)}") 