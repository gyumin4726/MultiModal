import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import warnings

# VMamba ê´€ë ¨ ì„í¬íŠ¸ ì‹œë„
VMAMBA_AVAILABLE = False
try:
    # vmamba.pyì—ì„œ í•„ìš”í•œ í´ë˜ìŠ¤ë“¤ì„ ì§ì ‘ ì„í¬íŠ¸
    import sys
    import os
    
    # VMamba íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    vmamba_path = os.path.join(os.path.dirname(__file__), 'vmamba.py')
    if os.path.exists(vmamba_path):
        sys.path.insert(0, os.path.dirname(__file__))
        from vmamba import vmamba_tiny_s1l8, VSSM
        VMAMBA_AVAILABLE = True
        print("âœ… VMamba loaded successfully from vmamba.py")
    else:
        print("âŒ vmamba.py not found in current directory")
except ImportError as e:
    print(f"Warning: VMamba import failed - {e}")
except Exception as e:
    print(f"Warning: VMamba loading error - {e}")

# Fallback: ResNet ë°±ë³¸ (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
try:
    import torchvision.models as models
    RESNET_AVAILABLE = True
except ImportError:
    RESNET_AVAILABLE = False


class VMambaBackbone(nn.Module):
    """VMamba ë°±ë³¸ (vmamba.py ì‚¬ìš©)"""
    
    def __init__(self, model_name='vmamba_tiny_s1l8', pretrained=True, output_dim=768):
        super().__init__()
        
        if not VMAMBA_AVAILABLE:
            raise ImportError("VMamba not available. Please ensure vmamba.py is in the current directory.")
        
        self.model_name = model_name
        self.output_dim = output_dim
        
        # VMamba ëª¨ë¸ ìƒì„±
        print(f"ğŸ”§ Creating VMamba model: {model_name}")
        if model_name == 'vmamba_tiny_s1l8':
            print(f"   Using vmamba_tiny_s1l8 with pretrained={pretrained}")
            self.backbone = vmamba_tiny_s1l8(pretrained=pretrained, channel_first=True)
            print(f"   âœ… vmamba_tiny_s1l8 model created successfully")
        else:
            print(f"   Using VSSM class with custom config")
            # ê¸°ë³¸ì ìœ¼ë¡œ VSSM í´ë˜ìŠ¤ ì‚¬ìš©
            self.backbone = VSSM(
                depths=[2, 2, 8, 2], 
                dims=96, 
                drop_path_rate=0.2,
                patch_size=4, 
                in_chans=3, 
                num_classes=1000,
                ssm_d_state=1, 
                ssm_ratio=1.0, 
                ssm_dt_rank="auto", 
                ssm_act_layer="silu",
                ssm_conv=3, 
                ssm_conv_bias=False, 
                ssm_drop_rate=0.0,
                ssm_init="v0", 
                forward_type="v05_noz",
                mlp_ratio=4.0, 
                mlp_act_layer="gelu", 
                mlp_drop_rate=0.0, 
                gmlp=False,
                patch_norm=True, 
                norm_layer="ln2d",
                downsample_version="v3", 
                patchembed_version="v2",
                use_checkpoint=False, 
                posembed=False, 
                imgsize=224,
            )
        
        # classifier ì œê±°í•˜ê³  feature extractorë¡œ ì‚¬ìš©
        if hasattr(self.backbone, 'classifier'):
            del self.backbone.classifier
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì°¨ì› í™•ì¸
        self.feature_dim = self._get_feature_dim()
        
        # ì¶œë ¥ ì°¨ì› ì¡°ì •ì„ ìœ„í•œ projection layer
        if self.feature_dim != output_dim:
            self.projection = nn.Linear(self.feature_dim, output_dim)
        else:
            self.projection = None
            
        print(f"VMamba backbone initialized: {model_name}")
        print(f"Feature dimension: {self.feature_dim} -> {output_dim}")
    
    def load_pretrained_weights(self, pretrained_path):
        """VMamba ì „ìš© ê°€ì¤‘ì¹˜ ë¡œë”©"""
        print(f"ğŸ“¥ Loading VMamba weights from: {pretrained_path}")
        try:
            checkpoint = torch.load(pretrained_path, map_location='cpu')
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                state_dict = checkpoint
            
            # ì§ì ‘ backboneì— ë¡œë”© (ì ‘ë‘ì‚¬ ì—†ì´)
            missing_keys, unexpected_keys = self.backbone.load_state_dict(state_dict, strict=False)
            
            print(f"   âœ… Loaded VMamba weights")
            print(f"   ğŸ“Š Missing keys: {len(missing_keys)}")
            print(f"   ğŸ“Š Unexpected keys: {len(unexpected_keys)}")
            
            if len(missing_keys) > 0:
                print(f"   âš ï¸ Missing keys (first 5): {missing_keys[:5]}")
            if len(unexpected_keys) > 0:
                print(f"   âš ï¸ Unexpected keys (first 5): {unexpected_keys[:5]}")
                
        except Exception as e:
            print(f"   âŒ Failed to load VMamba weights: {e}")
    
    def _get_feature_dim(self):
        """ë°±ë³¸ì˜ í”¼ì²˜ ì°¨ì› í™•ì¸"""
        try:
            # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì°¨ì› í™•ì¸
            dummy_input = torch.randn(1, 3, 224, 224)
            with torch.no_grad():
                features = self.extract_features(dummy_input)
                return features.shape[1]
        except:
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return 768
    
    def extract_features(self, x):
        """VMambaì—ì„œ í”¼ì²˜ ì¶”ì¶œ"""
        # patch embedding
        x = self.backbone.patch_embed(x)
        
        # position embedding (ìˆë‹¤ë©´)
        if hasattr(self.backbone, 'pos_embed') and self.backbone.pos_embed is not None:
            pos_embed = self.backbone.pos_embed
            x = x + pos_embed
        
        # ê° ë ˆì´ì–´ í†µê³¼
        for layer in self.backbone.layers:
            x = layer(x)
        
        # Global Average Pooling
        if len(x.shape) == 4:  # (B, C, H, W)
            x = torch.mean(x, dim=(2, 3))  # (B, C)
        elif len(x.shape) == 3:  # (B, H*W, C) ë˜ëŠ” (B, C, H*W)
            if x.shape[1] > x.shape[2]:  # (B, H*W, C)
                x = torch.mean(x, dim=1)  # (B, C)
            else:  # (B, C, H*W)
                x = torch.mean(x, dim=2)  # (B, C)
        
        return x
    
    def forward(self, x):
        features = self.extract_features(x)
        
        if self.projection is not None:
            features = self.projection(features)
            
        return features


class ResNetBackbone(nn.Module):
    """ResNet ë°±ë³¸ (Fallback)"""
    
    def __init__(self, model_name='resnet50', pretrained=True, output_dim=768):
        super().__init__()
        
        if not RESNET_AVAILABLE:
            raise ImportError("torchvision not available")
        
        # ResNet ëª¨ë¸ ë¡œë”©
        if model_name == 'resnet18':
            self.backbone = models.resnet18(pretrained=pretrained)
            feature_dim = 512
        elif model_name == 'resnet34':
            self.backbone = models.resnet34(pretrained=pretrained)
            feature_dim = 512
        elif model_name == 'resnet50':
            self.backbone = models.resnet50(pretrained=pretrained)
            feature_dim = 2048
        else:
            self.backbone = models.resnet50(pretrained=pretrained)
            feature_dim = 2048
        
        # classifier ì œê±°
        self.backbone.fc = nn.Identity()
        
        # ì¶œë ¥ ì°¨ì› ì¡°ì •
        if feature_dim != output_dim:
            self.projection = nn.Linear(feature_dim, output_dim)
        else:
            self.projection = None
            
        print(f"ResNet backbone initialized: {model_name}")
        print(f"Feature dimension: {feature_dim} -> {output_dim}")
    
    def forward(self, x):
        features = self.backbone(x)
        
        if self.projection is not None:
            features = self.projection(features)
            
        return features


class MambaNeck(nn.Module):
    """Mamba ê¸°ë°˜ Feature Neck (ê°„ë‹¨í™”ëœ ë²„ì „)"""
    
    def __init__(self, in_dim=768, out_dim=768, hidden_dim=512):
        super().__init__()
        
        self.in_dim = in_dim
        self.out_dim = out_dim
        
        # ê°„ë‹¨í•œ MLP ê¸°ë°˜ ë³€í™˜
        self.neck = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, out_dim),
            nn.LayerNorm(out_dim)
        )
        
    def forward(self, x):
        return self.neck(x)


class VisionEncoder(nn.Module):
    """í†µí•© Vision Encoder"""
    
    def __init__(self, 
                 model_name='vmamba_tiny_s1l8',
                 pretrained_path=None,
                 output_dim=768,
                 frozen_stages=-1,
                 use_neck=True):
        super().__init__()
        
        self.model_name = model_name
        self.output_dim = output_dim
        self.frozen_stages = frozen_stages
        
        # ë°±ë³¸ ì„ íƒ
        if VMAMBA_AVAILABLE and model_name.startswith('vmamba'):
            print("ğŸ”¥ Using VMamba backbone")
            self.backbone = VMambaBackbone(
                model_name=model_name,
                pretrained=False,  # ë‚´ë¶€ ë‹¤ìš´ë¡œë“œ ë°©ì§€
                output_dim=output_dim if not use_neck else 768
            )
            backbone_dim = 768
            
            # ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë”© (VMambaBackboneì—ì„œ ì§ì ‘ ì²˜ë¦¬)
            if pretrained_path and os.path.exists(pretrained_path):
                self.backbone.load_pretrained_weights(pretrained_path)
        else:
            print("âš ï¸ VMamba not available, using ResNet backbone")
            resnet_name = 'resnet50' if 'base' in model_name else 'resnet18'
            self.backbone = ResNetBackbone(
                model_name=resnet_name,
                pretrained=True,
                output_dim=output_dim if not use_neck else 768
            )
            backbone_dim = 768
        
        # Neck ì¶”ê°€ (ì„ íƒì )
        if use_neck:
            self.neck = MambaNeck(
                in_dim=backbone_dim,
                out_dim=output_dim,
                hidden_dim=512
            )
        else:
            self.neck = None
        
        # ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë”© (VMambaëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)
        print(f"ğŸ” Checking pretrained weights...")
        if pretrained_path:
            print(f"   Pretrained path specified: {pretrained_path}")
            if os.path.exists(pretrained_path):
                if not (VMAMBA_AVAILABLE and model_name.startswith('vmamba')):
                    # VMambaê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¼ë°˜ì ì¸ ê°€ì¤‘ì¹˜ ë¡œë”© ìˆ˜í–‰
                    print(f"   âœ… Pretrained file found, loading...")
                    self.load_pretrained_weights(pretrained_path)
                else:
                    print(f"   âœ… VMamba weights already loaded by backbone")
            else:
                print(f"   âŒ Pretrained file not found: {pretrained_path}")
                print(f"   ğŸ”„ Using default initialization")
        else:
            print(f"   â„¹ï¸ No pretrained path specified, using default weights")
        
        # ì¼ë¶€ ë ˆì´ì–´ ê³ ì •
        if frozen_stages >= 0:
            self.freeze_stages(frozen_stages)
    
    def load_pretrained_weights(self, path):
        """ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë”©"""
        print(f"ğŸ“¥ Loading pretrained weights from: {path}")
        try:
            print(f"   ğŸ“‚ Reading checkpoint file...")
            checkpoint = torch.load(path, map_location='cpu')
            print(f"   âœ… Checkpoint loaded successfully")
            
            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸
            print(f"   ğŸ” Analyzing checkpoint structure...")
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
                print(f"   ğŸ“¦ Using 'model' key from checkpoint")
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print(f"   ğŸ“¦ Using 'state_dict' key from checkpoint")
            else:
                state_dict = checkpoint
                print(f"   ğŸ“¦ Using checkpoint directly as state_dict")
            
            print(f"   ğŸ“Š Checkpoint contains {len(state_dict)} parameters")
            
            # í˜¸í™˜ë˜ëŠ” í‚¤ë§Œ ë¡œë”©
            print(f"   ğŸ”„ Filtering compatible parameters...")
            model_dict = self.state_dict()
            filtered_dict = {}
            
            compatible_count = 0
            incompatible_count = 0
            
            for k, v in state_dict.items():
                # VMamba ì²´í¬í¬ì¸íŠ¸ëŠ” backbone. ì ‘ë‘ì‚¬ê°€ ì—†ìœ¼ë¯€ë¡œ ì¶”ê°€
                target_key = f"backbone.{k}"
                found = False
                
                if target_key in model_dict:
                    if model_dict[target_key].shape == v.shape:
                        filtered_dict[target_key] = v
                        compatible_count += 1
                        found = True
                    else:
                        print(f"   âš ï¸ Shape mismatch for {target_key}: model={model_dict[target_key].shape} vs checkpoint={v.shape}")
                        incompatible_count += 1
                        found = True
                
                # ì›ë³¸ í‚¤ë„ ì‹œë„ (í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°)
                if not found:
                    if k in model_dict:
                        if model_dict[k].shape == v.shape:
                            filtered_dict[k] = v
                            compatible_count += 1
                            found = True
                        else:
                            print(f"   âš ï¸ Shape mismatch for {k}: model={model_dict[k].shape} vs checkpoint={v.shape}")
                            incompatible_count += 1
                            found = True
                
                if not found:
                    print(f"   âš ï¸ Key not found in model: {k} (tried: backbone.{k}, {k})")
                    incompatible_count += 1
            
            print(f"   ğŸ“ˆ Parameter matching results:")
            print(f"      Compatible: {compatible_count}")
            print(f"      Incompatible: {incompatible_count}")
            print(f"      Total in checkpoint: {len(state_dict)}")
            print(f"      Match rate: {compatible_count/len(state_dict)*100:.1f}%")
            
            # ì‹¤ì œ ë¡œë”©
            if compatible_count > 0:
                model_dict.update(filtered_dict)
                self.load_state_dict(model_dict, strict=False)
                print(f"   âœ… Successfully loaded {compatible_count} parameters")
            else:
                print(f"   âŒ No compatible parameters found, using random initialization")
            
        except Exception as e:
            print(f"   âŒ Failed to load pretrained weights: {e}")
            import traceback
            traceback.print_exc()
    
    def freeze_stages(self, frozen_stages):
        """ì§€ì •ëœ ìŠ¤í…Œì´ì§€ê¹Œì§€ ê°€ì¤‘ì¹˜ ê³ ì •"""
        if frozen_stages >= 0:
            # ë°±ë³¸ì˜ ì´ˆê¸° ë ˆì´ì–´ë“¤ ê³ ì •
            for name, param in self.backbone.named_parameters():
                param.requires_grad = False
            print(f"ğŸ§Š Frozen backbone parameters")
    
    def forward(self, x):
        # ì…ë ¥ì´ ì´ë¯¸ì§€ ê²½ë¡œì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(x, str):
            x = self.preprocess_image(x)
        
        # ë°±ë³¸ì„ í†µí•œ í”¼ì²˜ ì¶”ì¶œ
        features = self.backbone(x)
        
        # Neck ì ìš© (ìˆë‹¤ë©´)
        if self.neck is not None:
            features = self.neck(features)
        
        return features
    
    def preprocess_image(self, image_path):
        """ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í…ì„œë¡œ ë³€í™˜"""
        try:
            # ì´ë¯¸ì§€ ë¡œë”© ë° ì „ì²˜ë¦¬
            image = Image.open(image_path).convert("RGB")
            
            # ì „ì²˜ë¦¬ transform
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])
            
            image_tensor = transform(image).unsqueeze(0)  # (1, 3, 224, 224)
            
            # GPUë¡œ ì´ë™ (ê°€ëŠ¥í•œ ê²½ìš°)
            if torch.cuda.is_available():
                image_tensor = image_tensor.cuda()
                
            return image_tensor
            
        except Exception as e:
            print(f"Error preprocessing image {image_path}: {e}")
            # ë”ë¯¸ í…ì„œ ë°˜í™˜
            dummy = torch.randn(1, 3, 224, 224)
            if torch.cuda.is_available():
                dummy = dummy.cuda()
            return dummy


def load_vision_encoder(model_name='vmamba_tiny_s1l8', **kwargs):
    """Vision Encoder ë¡œë”© í•¨ìˆ˜"""
    return VisionEncoder(model_name=model_name, **kwargs)


# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
AVAILABLE_MODELS = {
    'vmamba_tiny_s1l8': {
        'description': 'VMamba Tiny model with s1l8 configuration',
        'pretrained_url': 'https://github.com/MzeroMiko/VMamba/releases/download/%23v2cls/vssm1_tiny_0230s_ckpt_epoch_264.pth',
    },
    'resnet18': {
        'description': 'ResNet-18 backbone (fallback)',
    },
    'resnet50': {
        'description': 'ResNet-50 backbone (fallback)',
    },
}

def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    print("ğŸ“‹ Available Vision Encoder models:")
    print("-" * 50)
    for model_name, info in AVAILABLE_MODELS.items():
        status = "âœ…" if (VMAMBA_AVAILABLE and 'vmamba' in model_name) or ('resnet' in model_name and RESNET_AVAILABLE) else "âŒ"
        print(f"{status} {model_name}")
        print(f"   - {info['description']}")
        if 'pretrained_url' in info:
            print(f"   - Pretrained: {info['pretrained_url']}")
        print()


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    list_available_models()
    
    # Vision Encoder í…ŒìŠ¤íŠ¸
    encoder = load_vision_encoder()
    
    # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    dummy_image = torch.randn(1, 3, 224, 224)
    features = encoder(dummy_image)
    print(f"Vision features shape: {features.shape}")
    print(f"Features norm: {features.norm()}") 